# =============================================================================
# RAG Q&A System - Python Dependencies
# =============================================================================
# Python Version: 3.9 - 3.11 recommended
# Install: pip install -r requirements.txt
# =============================================================================

# Core LangChain dependencies
langchain>=0.1.0
langchain-community>=0.0.10
langchain-core>=0.1.0

# Document processing
pypdf>=3.0.0
faiss-cpu>=1.7.0

# Text splitting and embeddings
sentence-transformers>=2.2.0
transformers>=4.30.0

# Google Generative AI (for API mode)
langchain-google-genai>=1.0.0
google-generativeai>=0.3.0

# Hugging Face embeddings (for local mode)
langchain-huggingface>=0.0.1

# Ollama integration (recommended for local models)
langchain-ollama>=0.1.0

# Environment management
python-dotenv>=1.0.0

# Deep learning framework (for embeddings and model inference)
torch>=2.0.0
numpy>=1.24.0

# Streamlit GUI dependencies
streamlit>=1.28.0
PyMuPDF>=1.23.0  # PDF preview and rendering
Pillow>=10.0.0   # Image processing

# Additional utilities for better compatibility
protobuf>=3.20.0  # Required by Google API
tiktoken>=0.5.0   # Tokenizer for better text processing (optional but recommended)

# Database (SQLite - included in Python standard library, no extra install needed)
# Memory management uses sqlite3 module from standard library

# =============================================================================
# Additional System Dependencies (install separately):
# =============================================================================
# 1. Ollama (for local LLM support):
#    Linux/WSL: curl -fsSL https://ollama.ai/install.sh | sh
#    macOS: brew install ollama
#    Windows: Download from https://ollama.ai/download
#    
#    After installation, pull models:
#    ollama pull phi3:mini
#    ollama pull gemma:2b
#
# 2. CUDA Toolkit (optional, for GPU acceleration):
#    Required for faster embeddings and local model inference
#    Install from: https://developer.nvidia.com/cuda-downloads
#    Then install: pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
# =============================================================================